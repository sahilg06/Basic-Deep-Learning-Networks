{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Theme_Classification_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-2BCA2OZlL"
      },
      "source": [
        "<h2> Theme classification</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zag_ccIuC1BW"
      },
      "source": [
        "#Importing requires libraries\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.utils import shuffle\n",
        "from\tsklearn.model_selection\timport GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKETa_7SOiXZ"
      },
      "source": [
        "<h3>Reading datasets</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHAoEU8D1Zy"
      },
      "source": [
        "df1=pd.read_excel(\"/content/dev_data_article.xlsx\")\n",
        "df2=pd.read_excel(\"/content/dev_data_tweet.xlsx\")\n",
        "df3=pd.read_excel(\"/content/evaluation_data.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee7Wax2CERQ5"
      },
      "source": [
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rpk0qb5D92J"
      },
      "source": [
        "#Clean data in tweets\n",
        "def clean(df,feature):\n",
        "    for i in range(len(df[feature])):\n",
        "\n",
        "        if 'RT' in df[feature][i]:\n",
        "            df[feature][i]=df[feature][i].split('RT')[1]\n",
        "        if 'QT' in df[feature][i]:\n",
        "            df[feature][i]=df[feature][i].split('QT')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id4o_vb4Eau2",
        "outputId": "39dd8720-4f85-4cf5-dea2-8f167bc34350"
      },
      "source": [
        "!pip install contractions\n",
        "import contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.48)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsHlXYXjOtyf"
      },
      "source": [
        "<h3>Common cleaning for articles and tweets</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi6bT-wsEdqI"
      },
      "source": [
        "#Common cleaning for articles and tweets\n",
        "def preprocess(df , feature):\n",
        "  \n",
        "  #removing urls\n",
        "  \n",
        "  df[feature]  = df[feature].apply(lambda x: re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
        "\n",
        "  #expanding contractions\n",
        "  df[feature] = df[feature].apply(lambda x:contractions.fix(x))\n",
        "\n",
        "  #lower case\n",
        "  df[feature] = df[feature].apply(lambda x:x.lower())\n",
        "\n",
        "  #removing digits and punctuations\n",
        "  df[feature] = df[feature].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
        "  df[feature] = df[feature].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
        "\n",
        "  #removing newlines\n",
        "  df[feature] = df[feature].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
        "\n",
        "  # removing extra spaces\n",
        "  df[feature] = df[feature].apply(lambda x: re.sub(' +',' ',x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5xKao_uEguW",
        "outputId": "8a4453ca-2d8c-4136-97dd-db1e321ed9da"
      },
      "source": [
        "preprocess(df1,'Text')\n",
        "preprocess(df1,'Headline')\n",
        "clean(df2,'Tweet')\n",
        "preprocess(df2,'Tweet')\n",
        "clean(df3,'Text')\n",
        "preprocess(df3,'Text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU9cJTpNO2ei"
      },
      "source": [
        "<h3>using headlines instead of articles to train the model in case of too short or meaningless articles</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vScpo7B_EsbH",
        "outputId": "ef647533-a66f-49e3-9a9d-2a3f5067a403"
      },
      "source": [
        "#using headlines instead of articles in case of too short or meaningless articles\n",
        "\n",
        "bad_strings = [\"by continuing to use the site you agree to the use of cookies you can find out more by clicking this link\",\n",
        "               \"we use cookies for analytics advertising and to improve our site you agree to our use of cookies by continuing to use our site to know more see our cookie policy and cookie settings\"\n",
        "              ]\n",
        "\n",
        "for ind, i in df1.iterrows():\n",
        "    if (len(i[\"Text\"]) < 60 or i[\"Text\"] in bad_strings) and len(i[\"Headline\"])!=0 :\n",
        "        df1[\"Text\"][ind] = df1[\"Headline\"][ind]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcUkLm3NPGX3"
      },
      "source": [
        "<h3>combining artciles and tweets to make a large training dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6UvJd6DFACo"
      },
      "source": [
        "#combining artciles and tweets to make a large training dataset\n",
        "df1 = df1.drop(\"Headline\",1)\n",
        "df2 = df2.rename(columns={\"Tweet_ID\" : \"Text_ID\" , \"Tweet\" : \"Text\", \"Mobile_Tech_Tag\":\"Mobile_Tech_Flag\"})\n",
        "df_combine =  pd.concat([df1,df2],0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GNtHH8GL5CZ"
      },
      "source": [
        "indexes=[]\n",
        "for i in range(len(df_combine['Text'])):\n",
        "  indexes.append(i)\n",
        "df_combine=df_combine.set_index(np.asarray(indexes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAXnACnuFqvY",
        "outputId": "e4cf3b35-df82-4076-b16e-157160ade274"
      },
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhXqbxPhPOsc"
      },
      "source": [
        "<h3> Generating Embeddings</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZvrGyIMFy6y",
        "outputId": "48bd0749-46ad-4c55-e37c-5a906923109c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
        "query_embeddings = model.encode(df_combine['Text'])\n",
        "test_embeddings = model.encode(df3['Text'])\n",
        "print(query_embeddings.shape)\n",
        "print(test_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 512)\n",
            "(432, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i6B1KK6IWMG",
        "outputId": "54f775bb-3120-4719-88fb-a66a6dc9abe5"
      },
      "source": [
        "# Use cuda if present\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3sK2S5DMfkP"
      },
      "source": [
        "rand =20\n",
        "embedded = query_embeddings\n",
        "labels = df_combine['Mobile_Tech_Flag']\n",
        "embedded, label = shuffle(embedded, labels, random_state=rand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XcWT6IeKJ_Y",
        "outputId": "7fdcf47b-be1a-44cc-a2d2-9ae500c274f8"
      },
      "source": [
        "X_train = embedded\n",
        "Y_train = label.values\n",
        "X_test = test_embeddings\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 512)\n",
            "(8000,)\n",
            "(432, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6sGB2ZRPb7p"
      },
      "source": [
        "<h3>Training and Predicting</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-4a1-GPKL1U",
        "outputId": "1baf85fc-7b52-434f-abb3-0a570caa2493"
      },
      "source": [
        "X_train_t = torch.tensor(X_train).to(device)\n",
        "Y_train_t = torch.tensor(Y_train).to(device)\n",
        "test_data = torch.tensor(X_test).to(device)\n",
        "\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC(kernel=\"rbf\",probability=True)\n",
        "voting_clf = VotingClassifier(\n",
        " estimators=[\n",
        "             ('rf', rnd_clf), ('svc', svm_clf) ],\n",
        " voting='soft'\n",
        " )\n",
        "voting_clf.fit(X_train_t.cpu(), Y_train_t.cpu())\n",
        "y_pred_vote = voting_clf.predict(test_data.cpu())\n",
        "y_pred_vote"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arvWgy_aKt5g",
        "outputId": "9125d3cf-44d3-468c-b1da-4ceeac5348eb"
      },
      "source": [
        "end= time.time()\n",
        "print(\"Runtime:\",end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Runtime: 99.06230044364929\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}